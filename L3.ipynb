{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c10b768-f5b4-43bc-a785-99077422ce78",
   "metadata": {},
   "source": [
    "# å¯«ä¸€éš»èŠå¤©æ©Ÿå™¨äºº/Write a chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d4fedc-4b90-4754-9f2d-fd3cfa321a14",
   "metadata": {},
   "source": [
    "åœ¨é€™å ‚èª²ä¸­ï¼Œä½ å°‡ç†Ÿæ‚‰ä½ åœ¨æœ¬èª²ç¨‹ä¸­æœƒç”¨åˆ°çš„èŠå¤©æ©Ÿå™¨äººç¯„ä¾‹ã€‚é€™å€‹ç¯„ä¾‹åŒ…å«å·¥å…·çš„å®šç¾©èˆ‡åŸ·è¡Œï¼Œä»¥åŠèŠå¤©æ©Ÿå™¨äººçš„ç¨‹å¼ç¢¼ã€‚è«‹å‹™å¿…åœ¨æœ¬ç­†è¨˜æœ¬çš„çµå°¾èˆ‡èŠå¤©æ©Ÿå™¨äººé€²è¡Œäº’å‹•ã€‚\n",
    "\n",
    "In this lesson, you will familiarize yourself with the chatbot example you will work on during this course. The example includes the tool definitions and execution, as well as the chatbot code. Make sure to interact with the chatbot at the end of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ed96ba-5ade-4af4-9096-406ce48d5cf2",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d4fb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install arxiv dotenv anthropic install google-api-python-client google-generativeai protobuf==5.27.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9474eae",
   "metadata": {},
   "source": [
    "è«‹å°‡æ‚¨çš„ API é‡‘é‘°è¨­å®šåœ¨ cred.py æª”æ¡ˆä¸­\n",
    "\n",
    "Remember to set your API keys in the `cred.py` file.\n",
    "Content as below\n",
    "\n",
    "keys = {'GEMINI_API_KEY':'XXX',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6bd1d4-f652-45d1-9efa-155a2cc01713",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\test1\\Development\\.mcp_venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import anthropic\n",
    "import cred \n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20f163a-87af-4e0c-87ed-1624c150c572",
   "metadata": {},
   "source": [
    "## Tool Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "549a7f46-74b3-4a1d-b084-055c99e3c318",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_DIR = \"papers\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e43905e-56f3-404c-a322-f038055e9b1c",
   "metadata": {},
   "source": [
    "ç¬¬ä¸€å€‹å·¥å…·æœƒæ ¹æ“šä¸€å€‹ä¸»é¡Œï¼Œæœå°‹ç›¸é—œçš„ arXiv è«–æ–‡ï¼Œä¸¦å°‡è«–æ–‡çš„è³‡è¨Šï¼ˆæ¨™é¡Œã€ä½œè€…ã€æ‘˜è¦ã€è«–æ–‡ç¶²å€å’Œç™¼è¡¨æ—¥æœŸï¼‰å„²å­˜æˆ JSON æª”æ¡ˆã€‚é€™äº› JSON æª”æ¡ˆæœƒä¾ä¸»é¡Œåˆ†é¡ï¼Œå­˜æ”¾åœ¨ `papers` ç›®éŒ„ä¸­ã€‚é€™å€‹å·¥å…·ä¸¦ä¸æœƒä¸‹è¼‰è«–æ–‡ã€‚\n",
    "\n",
    "The first tool searches for relevant arXiv papers based on a topic and stores the papers' info in a JSON file (title, authors, summary, paper url and the publication date). The JSON files are organized by topics in the `papers` directory. The tool does not download the papers. Â "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886633b8-ce67-4343-822d-cc3f98f953fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_papers(topic: str, max_results: float = 5.0) -> List[str]:\n",
    "    \"\"\"\n",
    "    æœå°‹ ArXiv è«–æ–‡ï¼Œæ ¹æ“šä¸€å€‹ä¸»é¡Œåœ¨ ArXiv ä¸Šæœå°‹è«–æ–‡ä¸¦å„²å­˜å…¶è³‡è¨Šã€‚\n",
    "\n",
    "    åƒæ•¸\n",
    "        topicï¼šè¦æœå°‹çš„ä¸»é¡Œ\n",
    "\n",
    "        max_resultsï¼šè¦æª¢ç´¢çš„æœ€å¤§çµæœæ•¸ï¼ˆé è¨­å€¼ï¼š5ï¼‰\n",
    "\n",
    "    å›å‚³å€¼\n",
    "        æœå°‹ä¸­æ‰¾åˆ°çš„è«–æ–‡ ID åˆ—è¡¨\n",
    "\n",
    "    Search for papers on arXiv based on a topic and store their information.\n",
    "    \n",
    "    Args:\n",
    "        topic: The topic to search for\n",
    "        max_results: Maximum number of results to retrieve (default: 5)\n",
    "        \n",
    "    Returns:\n",
    "        List of paper IDs found in the search\n",
    "    \"\"\"\n",
    "    max_results = int(max_results)  # Ensure max_results is an integer\n",
    "    # Use arxiv to find the papers \n",
    "    client = arxiv.Client()\n",
    "    if max_results <= 0:\n",
    "        raise ValueError(\"max_results must be greater than 0\")\n",
    "\n",
    "    # Search for the most relevant articles matching the queried topic\n",
    "    search = arxiv.Search(\n",
    "        query = topic,\n",
    "        max_results = max_results,\n",
    "        sort_by = arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "    # print(topic, max_results)\n",
    "    papers = client.results(search)\n",
    "    \n",
    "    # Create directory for this topic\n",
    "    path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    file_path = os.path.join(path, \"papers_info.json\")\n",
    "\n",
    "    # Try to load existing papers info\n",
    "    try:\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            papers_info = json.load(json_file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        papers_info = {}\n",
    "\n",
    "    # Process each paper and add to papers_info  \n",
    "    paper_ids = []\n",
    "    for paper in papers:\n",
    "        paper_ids.append(paper.get_short_id())\n",
    "        paper_info = {\n",
    "            'title': paper.title,\n",
    "            'authors': [author.name for author in paper.authors],\n",
    "            'summary': paper.summary,\n",
    "            'pdf_url': paper.pdf_url,\n",
    "            'published': str(paper.published.date())\n",
    "        }\n",
    "        papers_info[paper.get_short_id()] = paper_info\n",
    "    \n",
    "    # Save updated papers_info to json file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(papers_info, json_file, indent=2)\n",
    "    \n",
    "    print(f\"Results are saved in: {file_path}\")\n",
    "    \n",
    "    return paper_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d20ee17a-afe6-438a-95b1-6e87742c7fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are saved in: papers\\computers\\papers_info.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1310.7911v2',\n",
       " 'math/9711204v1',\n",
       " '2208.00733v1',\n",
       " '2504.07020v1',\n",
       " '2403.03925v1']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_papers(\"computers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb83565-69af-47f3-9ba3-a96965cff7df",
   "metadata": {},
   "source": [
    "ç¬¬äºŒå€‹å·¥å…·æœƒåœ¨ `papers` ç›®éŒ„ä¸‹ï¼Œæœå°‹æ‰€æœ‰ä¸»é¡Œè³‡æ–™å¤¾ä¸­ç‰¹å®šè«–æ–‡çš„è³‡è¨Šã€‚\n",
    "\n",
    "The second tool looks for information about a specific paper across all topic directories inside the `papers` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9b1997-81cd-447d-9665-1cb72d93bb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(paper_id: str) -> str:\n",
    "    \"\"\"\n",
    "    æœå°‹æŒ‡å®šè«–æ–‡\n",
    "    åœ¨æ‰€æœ‰ä¸»é¡Œç›®éŒ„ä¸­æœå°‹ç‰¹å®šè«–æ–‡çš„è³‡è¨Šã€‚\n",
    "\n",
    "    åƒæ•¸\n",
    "        paper_idï¼šè¦å°‹æ‰¾çš„è«–æ–‡ ID\n",
    "\n",
    "    å›å‚³å€¼\n",
    "        å¦‚æœæ‰¾åˆ°è«–æ–‡ï¼Œå‰‡å›å‚³åŒ…å«è«–æ–‡è³‡è¨Šçš„ JSON å­—ä¸²ï¼›å¦‚æœæ‰¾ä¸åˆ°ï¼Œå‰‡å›å‚³éŒ¯èª¤è¨Šæ¯ã€‚\n",
    "\n",
    "    Search for information about a specific paper across all topic directories.\n",
    "    \n",
    "    Args:\n",
    "        paper_id: The ID of the paper to look for\n",
    "        \n",
    "    Returns:\n",
    "        JSON string with paper information if found, error message if not found\n",
    "    \"\"\"\n",
    " \n",
    "    for item in os.listdir(PAPER_DIR):\n",
    "        item_path = os.path.join(PAPER_DIR, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with open(file_path, \"r\") as json_file:\n",
    "                        papers_info = json.load(json_file)\n",
    "                        if paper_id in papers_info:\n",
    "                            return json.dumps(papers_info[paper_id], indent=2)\n",
    "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    return f\"There's no saved information related to paper {paper_id}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ebe0de7-8f07-4e08-a670-7b371fc3d2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"title\": \"Compact manifolds with computable boundaries\",\\n  \"authors\": [\\n    \"Zvonko Iljazovic\"\\n  ],\\n  \"summary\": \"We investigate conditions under which a co-computably enumerable closed set\\\\nin a computable metric space is computable and prove that in each locally\\\\ncomputable computable metric space each co-computably enumerable compact\\\\nmanifold with computable boundary is computable. In fact, we examine the notion\\\\nof a semi-computable compact set and we prove a more general result: in any\\\\ncomputable metric space each semi-computable compact manifold with computable\\\\nboundary is computable. In particular, each semi-computable compact\\\\n(boundaryless) manifold is computable.\",\\n  \"pdf_url\": \"http://arxiv.org/pdf/1310.7911v2\",\\n  \"published\": \"2013-10-29\"\\n}'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_info('1310.7911v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ea3013-e690-4bc8-8622-27b4d42d61e4",
   "metadata": {},
   "source": [
    "## Tool Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7d2260-452d-472a-b56e-326479cb18c9",
   "metadata": {},
   "source": [
    "Here are the schema of each tool which you will provide to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "734f9b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "  {\n",
    "    \"function_declarations\": [\n",
    "      {\n",
    "        \"name\": \"search_papers\",\n",
    "        \"description\": \"Search for papers on arXiv based on a topic and store their information.\",\n",
    "        \"parameters\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "            \"topic\": {\n",
    "              \"type\": \"string\",\n",
    "              \"description\": \"The topic to search for\"\n",
    "            },\n",
    "            \"max_results\": {\n",
    "              \"type\": \"integer\",\n",
    "              \"description\": \"Maximum number of results to retrieve, must a int cannot be a float, default is 5, and value must be greater than 0\",\n",
    "            }\n",
    "          },\n",
    "          \"required\": [\n",
    "            \"topic\"\n",
    "          ]\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"extract_info\",\n",
    "        \"description\": \"Search for information about a specific paper across all topic directories.\",\n",
    "        \"parameters\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "            \"paper_id\": {\n",
    "              \"type\": \"string\",\n",
    "              \"description\": \"The ID of the paper to look for\"\n",
    "            }\n",
    "          },\n",
    "          \"required\": [\n",
    "            \"paper_id\"\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec668d24-1559-41b7-bc8a-e2dca77dfaf2",
   "metadata": {},
   "source": [
    "## Tool Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c728c1ec-36b1-48b4-9f85-622464ac79f4",
   "metadata": {},
   "source": [
    "è™•ç†å·¥å…·çš„æ˜ åƒè·ŸåŸ·è¡Œ\n",
    "\n",
    "This code handles tool mapping and execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c90790c0-efc4-4068-9c00-d2592d80bc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_tool_function = {\n",
    "    \"search_papers\": search_papers,\n",
    "    \"extract_info\": extract_info\n",
    "}\n",
    "\n",
    "def execute_tool(tool_name, tool_args):\n",
    "    \n",
    "    result = mapping_tool_function[tool_name](**tool_args)\n",
    "\n",
    "    if result is None:\n",
    "        result = \"The operation completed but didn't return any results.\"\n",
    "        \n",
    "    elif isinstance(result, list):\n",
    "        result = ', '.join(result)\n",
    "        \n",
    "    elif isinstance(result, dict):\n",
    "        # Convert dictionaries to formatted JSON strings\n",
    "        result = json.dumps(result, indent=2)\n",
    "    \n",
    "    else:\n",
    "        # For any other type, convert using str()\n",
    "        result = str(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8fc4d3-58ac-482c-8bbd-bccd6ef9fc31",
   "metadata": {},
   "source": [
    "## èŠå¤©æ©Ÿå™¨äººç¨‹å¼ç¢¼/Chatbot Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ba0fad-b0e4-4415-a431-341e9ca85087",
   "metadata": {},
   "source": [
    "é€™å€‹èŠå¤©æ©Ÿå™¨äººæœƒä¸€å€‹ä¸€å€‹è™•ç†ä½¿ç”¨è€…çš„å•é¡Œï¼Œä½†å®ƒä¸æœƒåœ¨ä¸åŒå•é¡Œä¹‹é–“ä¿ç•™è¨˜æ†¶ã€‚\n",
    "\n",
    "The chatbot handles the user's queries one by one, but it does not persist memory across the queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe662400-8506-464e-a3da-75a3d8848bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() \n",
    "client = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175586b4-acdf-4103-8039-134478a4f797",
   "metadata": {},
   "source": [
    "### åŸ·è¡Œæµç¨‹/Query Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91416aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query):\n",
    "    # é…ç½® API å¯†é‘°\n",
    "    genai.configure(api_key=cred.keys['GEMINI_API_KEY'])\n",
    "    \n",
    "    # åˆå§‹åŒ–æ¨¡å‹\n",
    "    model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\", tools=tools)\n",
    "\n",
    "    # åˆå§‹å°è©±è¨Šæ¯\n",
    "    messages = [{'role': 'user', 'parts': [query]}]\n",
    "    \n",
    "    process_query_loop = True\n",
    "    while process_query_loop:\n",
    "        # å‘¼å« generate_content\n",
    "        response = model.generate_content(messages)\n",
    "        \n",
    "        # æª¢æŸ¥å›æ‡‰å…§å®¹\n",
    "        for part in response.candidates[0].content.parts:\n",
    "            # è™•ç†æ–‡å­—å›æ‡‰\n",
    "            if part.text:\n",
    "                print(part.text)\n",
    "                # å¦‚æœåªæœ‰æ–‡å­—å›æ‡‰ï¼Œå‰‡çµæŸè¿´åœˆ\n",
    "                if len(response.candidates[0].content.parts) == 1:\n",
    "                    process_query_loop = False\n",
    "                \n",
    "            # è™•ç†å·¥å…·å‘¼å«\n",
    "            elif part.function_call:\n",
    "                tool_name = part.function_call.name\n",
    "                # å°‡ MapComposite ç‰©ä»¶è½‰æ›ç‚ºæ¨™æº–çš„ Python å­—å…¸\n",
    "                tool_args = dict(part.function_call.args) \n",
    "                print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
    "                \n",
    "                # å°‡åŠ©æ‰‹çš„å·¥å…·å‘¼å«åŠ å…¥åˆ°è¨Šæ¯æ­·å²ä¸­\n",
    "                messages.append({'role': 'model', 'parts': [part]})\n",
    "                \n",
    "                # åŸ·è¡Œå·¥å…·ä¸¦ç²å–çµæœ\n",
    "                result = execute_tool(tool_name, tool_args)\n",
    "                \n",
    "                # å°‡å·¥å…·çµæœåŠ å…¥åˆ°è¨Šæ¯æ­·å²ä¸­ï¼Œä»¥ä¾¿æ¨¡å‹èƒ½å¤ ç¹¼çºŒå°è©±\n",
    "                messages.append({\n",
    "                    \"role\": \"user\",\n",
    "                    \"parts\": [\n",
    "                        {\n",
    "                            \"function_response\": {\n",
    "                                \"name\": tool_name,\n",
    "                                \"response\": {\"content\": result}\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2921ee7f-d2be-464b-ab7b-8db2a3c13ba9",
   "metadata": {},
   "source": [
    "### å¾ªç’°å°è©±/Chat Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16979cdc-81e9-432b-ba7f-e810b52961e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop():\n",
    "    print(\"è¼¸å…¥æ‚¨çš„æŸ¥è©¢æˆ–è¼¸å…¥ 'quit' ä»¥é€€å‡ºã€‚\")\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nQuery: \").strip()\n",
    "            if query.lower() == 'quit':\n",
    "                break\n",
    "    \n",
    "            process_query(query)\n",
    "            print(\"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfaf254-f22a-4951-885e-1d21fbc41ff3",
   "metadata": {},
   "source": [
    "ä½ å¯ä»¥éš¨æ„èˆ‡é€™å€‹èŠå¤©æ©Ÿå™¨äººäº’å‹•ã€‚é€™è£¡æœ‰ä¸€å€‹ç¯„ä¾‹æŸ¥è©¢ï¼š\n",
    "\n",
    "- æœå°‹å…©ç¯‡é—œæ–¼ã€ŒLLM å¯è§£é‡‹æ€§ã€çš„è«–æ–‡\n",
    "\n",
    "è¦å­˜å– `papers` è³‡æ–™å¤¾ï¼Œè«‹ä¾ç…§ä»¥ä¸‹æ­¥é©Ÿï¼š\n",
    "\n",
    "1.  é»æ“Šç­†è¨˜æœ¬é ‚éƒ¨é¸å–®ä¸Šçš„ **`æª”æ¡ˆ` (File)** é¸é …ã€‚\n",
    "2.  é»æ“Š **`é–‹å•Ÿ` (Open)**ã€‚\n",
    "3.  é»æ“Š **`L3`**ã€‚\n",
    "\n",
    "Feel free to interact with the chatbot. Here's an example query: \n",
    "\n",
    "- Search for 2 papers on \"LLM interpretability\"\n",
    "\n",
    "To access the `papers` folder: 1) click on the `File` option on the top menu of the notebook and 2) click on `Open` and then 3) click on `L3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39676f70-1c72-4da3-8363-da281bd5a83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your queries or 'quit' to exit.\n",
      "Calling tool search_papers with args {'max_results': 5.0, 'topic': 'computer'}\n",
      "Results are saved in: papers\\computer\\papers_info.json\n",
      "Here's the information for the papers found:\n",
      "\n",
      "\n",
      "Calling tool extract_info with args {'paper_id': '1310.7911v2'}\n",
      "Calling tool extract_info with args {'paper_id': 'math/9711204v1'}\n",
      "Calling tool extract_info with args {'paper_id': '2208.00733v1'}\n",
      "Calling tool extract_info with args {'paper_id': '2504.07020v1'}\n",
      "Calling tool extract_info with args {'paper_id': '2403.03925v1'}\n",
      "Here are some papers about computers I found:\n",
      "\n",
      "* **Compact manifolds with computable boundaries:** This paper investigates conditions under which a co-computably enumerable closed set in a computable metric space is computable.\n",
      "* **Aspects of Computability in Physics:** This paper reviews connections between physics and computation, exploring topics such as computational hardness of physical systems and quantum computation.\n",
      "* **The Rise of Quantum Internet Computing:** This article discusses quantum internet computing, which involves distributed quantum computing over a quantum internet.\n",
      "* **Computably discrete represented spaces:** This paper explores computably discrete represented spaces in computable topology.\n",
      "* **Consciousness qua Mortal Computation:** This paper argues that consciousness is a type of computation called mortal computation.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34df7890-4b4c-4ec9-b06f-abc8c4a290e8",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> ğŸš¨\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by AI chat models can vary with each execution due to their dynamic, probabilistic nature. Don't be surprised if your results differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508916f3-8fa1-4e21-bfa7-081a810bc36c",
   "metadata": {},
   "source": [
    "In the next lessons, you will take out the tool definitions to wrap them in an MCP server. Then you will create an MCP client inside the chatbot to make the chatbot MCP compatible.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02d207b-e07d-49ff-bb03-7954aa86c167",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "[Guide on how to implement tool use](https://docs.anthropic.com/en/docs/build-with-claude/tool-use/overview#how-to-implement-tool-use)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mcp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
